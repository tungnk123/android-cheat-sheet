1. **Why do we use** **`suspend`** **functions in Kotlin? Why not just use callbacks or regular functions?**
	- `suspend` marks a function that can pause and resume without blocking the thread, letting you write asynchronous code sequentially and safely.
	- **No thread blocking:** Unlike long-running work on the main thread (which would freeze the UI), `suspend` allows work to move to another dispatcher (e.g., `Dispatchers.IO`) while the original thread remains free.
	- **Cleaner code than callbacks:** Callbacks create nested code (callback hell) and make error handling and sequencing harder. `suspend` functions let you write sequential-looking code (`val user = fetchUser()`), which is easier to read and maintain.
	- **Better error handling:** Use standard `try/catch` around `suspend` calls instead of handling errors in many callback callbacks.
	- **Composability:** `suspend` functions can be combined with coroutine builders (`launch`, `async`) and structured concurrency, making cancellations and scope lifecycle easier.
2. Flow vs LiveData:
	- LiveData = Hot + Stateful + Lifecycle-Aware
	- Operators and transformations:** `Flow` has a rich set of operators (`map`, `flatMapLatest`, `buffer`, `debounce`) to transform and combine streams. `LiveData` has `map`/`switchMap`, but fewer operators and less functional power.
	- **Backpressure handling:** `Flow` supports buffering, conflation, and sampling to handle producers faster than consumers. `LiveData` doesn't give such explicit control.
	- **Platform independence & testing:** `Flow` is pure Kotlin — usable in JVM modules, tests, and non-Android layers. `LiveData` is Android lifecycle-aware, so harder to use in plain unit tests without Android testing tools.
	-  **Interoperability with Coroutines:** `Flow` integrates naturally with coroutines and structured concurrency. You can `collect` within coroutine scopes and cancel easily.
3. Why doing CPU-heavy work on an IO pool (like `Dispatchers.IO`) is a problem.
	- **CPU pool** (`Default`, `Executors.newFixedThreadPool(#cores)`):
		- Size ≈ number of CPU cores.
		- Assumes threads will be doing **CPU work almost all the time**.
	- **IO pool** (`Dispatchers.IO`, cached pools, etc.):
		- Size is **larger** (e.g., 64 or more) because IO tasks **block** (sleep waiting for disk/network).
		- Assumes most threads spend time **idle, waiting on IO**, not burning CPU.
	- When you run CPU-heavy tasks on the IO pool:
		- Those extra threads **don’t magically add more CPUs**.
		- You just get **more threads fighting for the same cores**.
	- Starving real IO tasks
		- Threads are now **busy doing CPU** instead of quickly blocking on IO.
		- When real IO tasks arrive, they **wait in the queue** because all threads are busy.
	- A flood of CPU work on the IO pool:
		- Makes the system **feel sluggish**.
		- Introduces unpredictable latency spikes.
		- Makes performance tuning much harder (because the IO pool behavior becomes non-deterministic).
	- The OS keeps **rapidly switching** between threads:
	    - Each switch trashes CPU caches.
	    - Useful work per unit time goes **down**, even though CPU utilization looks high.
	- You can end up with **lower throughput** than if you had just used a small, fixed CPU pool.
	- **Higher latency** – slower responses, more timeouts/jank.
	- **Lower throughput** – more context switches, worse CPU cache usage.
4. Sqldelight with coroutine:
	- Add sqldelight coroutine extensions
	- queries.selectAll().asFlow().mapToList(Dispatchers.IO)